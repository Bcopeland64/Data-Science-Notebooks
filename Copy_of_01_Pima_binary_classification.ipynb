{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 01_Pima_binary_classification",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bcopeland64/Data-Science-Notebooks/blob/master/Copy_of_01_Pima_binary_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4CKPiy5eePy"
      },
      "source": [
        "Â© 2021 Zaka AI, Inc. All Rights Reserved"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sRIDoDPqJyUr"
      },
      "source": [
        "#Binary Classification\n",
        "\n",
        "**Objective:** The goal of this notebook is to build, train and evaluate a Deep Learning (DL) model on a real dataset. We will be doing a binary classification, which means the output of our neural network will be one neuron emitting either a 0 or 1.\n",
        "\n",
        "The required libraries for this exercise are `Keras` for building and training the DL model, `Numpy` for numerical handling and loading of the dataset and `scikit-learn` for validation and datasplit."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D7hsqQL6mXG0"
      },
      "source": [
        "## 1. Load data\n",
        "\n",
        "In this notebook, we are going to use the **Pima Indians diabetes** dataset. This is a standard machine learning dataset from the UCI Machine Learning repository. It describes patient medical record data for Pima Indians and whether they had an onset of diabetes within five years.\n",
        "\n",
        "As such, it is a binary classification problem (onset of diabetes as 1 or not as 0). All of the input variables that describe each patient are numerical. \n",
        "\n",
        "This makes it easy to use directly with neural networks that expect numerical input and output values, and ideal for our first neural network in Keras.\n",
        "\n",
        "The variables can be summarized as follows:\n",
        "\n",
        "**Input Variables (X):**\n",
        "\n",
        "\n",
        "1.   Number of times pregnant\n",
        "2.   Plasma glucose concentration a 2 hours in an oral glucose tolerance test\n",
        "3.   Diastolic blood pressure (mm Hg)\n",
        "4.   Triceps skin fold thickness (mm)\n",
        "5.   2-Hour serum insulin (mu U/ml)\n",
        "6.   Body mass index (weight in kg/(height in m)^2)\n",
        "7.   Diabetes pedigree function\n",
        "8.   Age (years)\n",
        "\n",
        "Output Variables (Y):\n",
        "\n",
        "*   Class variable (0 or 1)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuVahF7eloMV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c5e8e7b-2d28-44d6-9a37-fa2643d63594"
      },
      "source": [
        "# clone git repo\n",
        "!git clone https://github.com/zaka-ai/intro2dl.git\n",
        "\n",
        "# change directory\n",
        "%cd intro2dl/data/"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'intro2dl'...\n",
            "remote: Enumerating objects: 16, done.\u001b[K\n",
            "remote: Counting objects: 100% (16/16), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 16 (delta 1), reused 7 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (16/16), done.\n",
            "/content/intro2dl/data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIu3Id57luLl"
      },
      "source": [
        "import numpy\n",
        "\n",
        "# load pima indians dataset\n",
        "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
        "\n",
        "# split into input (X) and output (Y) variables\n",
        "X = dataset[:,0:8]\n",
        "Y = dataset[:,8]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FWrfBdRKnKlk"
      },
      "source": [
        "## 2. Define Keras Model\n",
        "\n",
        "Create a Keras Sequential model that has 2 hidden layers, with the `relu` activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxsfruZnnSH8"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def create_model():\n",
        "  # create model\n",
        "\n",
        "  model = Sequential() \n",
        "  model.add(Dense(12, input_dim=8, activation='relu'))   \n",
        "  model.add(Dense(8, activation='relu')) \n",
        "  model.add(Dense(1, activation=\"sigmoid\")) \n",
        "  \n",
        "\n",
        "  return model\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m89-8lpfnenc"
      },
      "source": [
        "## 3. Train Model\n",
        "\n",
        "Before training the model, we have to make sure it's compiled!\n",
        "\n",
        "Training occurs over epochs and each epoch is split into batches.\n",
        "\n",
        "*   **Epoch**: One pass through all of the rows in the training dataset.\n",
        "*   **Batch**: One or more samples considered by the model within an epoch before weights are updated\n",
        "\n",
        "\n",
        "Let's train the model for 150 epochs with batch size equals to 10."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rOX9fIslng06",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b93d93c-fbe2-4ad8-804d-368f1a4dbced"
      },
      "source": [
        "model = create_model()\n",
        "\n",
        "# Compile model with binary crossentropy\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='binary_crossentropy', # categorical crossentry, MSE = 0.5(y-y_hat)^2\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, Y, epochs=150, batch_size=10, verbose=1)\n",
        "\n",
        "print(\"Model trained!\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 2.3533 - accuracy: 0.6483\n",
            "Epoch 2/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6162 - accuracy: 0.6482\n",
            "Epoch 3/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6071 - accuracy: 0.6799\n",
            "Epoch 4/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6208 - accuracy: 0.6578\n",
            "Epoch 5/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6118 - accuracy: 0.6763\n",
            "Epoch 6/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6599 - accuracy: 0.6375\n",
            "Epoch 7/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6232 - accuracy: 0.6668\n",
            "Epoch 8/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6051 - accuracy: 0.6803\n",
            "Epoch 9/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6112 - accuracy: 0.6809\n",
            "Epoch 10/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6079 - accuracy: 0.6754\n",
            "Epoch 11/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6120 - accuracy: 0.6529\n",
            "Epoch 12/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5991 - accuracy: 0.6986\n",
            "Epoch 13/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6049 - accuracy: 0.6846\n",
            "Epoch 14/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5988 - accuracy: 0.6733\n",
            "Epoch 15/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6150 - accuracy: 0.6737\n",
            "Epoch 16/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5890 - accuracy: 0.6804\n",
            "Epoch 17/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6065 - accuracy: 0.6784\n",
            "Epoch 18/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5929 - accuracy: 0.6908\n",
            "Epoch 19/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6031 - accuracy: 0.6830\n",
            "Epoch 20/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5894 - accuracy: 0.6971\n",
            "Epoch 21/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5827 - accuracy: 0.7084\n",
            "Epoch 22/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5804 - accuracy: 0.7138\n",
            "Epoch 23/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5994 - accuracy: 0.6846\n",
            "Epoch 24/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6077 - accuracy: 0.6845\n",
            "Epoch 25/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6100 - accuracy: 0.6819\n",
            "Epoch 26/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5741 - accuracy: 0.7000\n",
            "Epoch 27/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5939 - accuracy: 0.6989\n",
            "Epoch 28/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5680 - accuracy: 0.6716\n",
            "Epoch 29/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6220 - accuracy: 0.6482\n",
            "Epoch 30/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5996 - accuracy: 0.6848\n",
            "Epoch 31/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6067 - accuracy: 0.6872\n",
            "Epoch 32/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5949 - accuracy: 0.6807\n",
            "Epoch 33/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5699 - accuracy: 0.7243\n",
            "Epoch 34/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6068 - accuracy: 0.6741\n",
            "Epoch 35/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6016 - accuracy: 0.7045\n",
            "Epoch 36/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5837 - accuracy: 0.7036\n",
            "Epoch 37/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5554 - accuracy: 0.7201\n",
            "Epoch 38/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6097 - accuracy: 0.6797\n",
            "Epoch 39/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6062 - accuracy: 0.6657\n",
            "Epoch 40/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6100 - accuracy: 0.6708\n",
            "Epoch 41/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5728 - accuracy: 0.6934\n",
            "Epoch 42/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5718 - accuracy: 0.7262\n",
            "Epoch 43/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6115 - accuracy: 0.6537\n",
            "Epoch 44/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6206 - accuracy: 0.6762\n",
            "Epoch 45/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5946 - accuracy: 0.6716\n",
            "Epoch 46/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5697 - accuracy: 0.6978\n",
            "Epoch 47/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6069 - accuracy: 0.6531\n",
            "Epoch 48/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6067 - accuracy: 0.6942\n",
            "Epoch 49/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5987 - accuracy: 0.6779\n",
            "Epoch 50/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5907 - accuracy: 0.6876\n",
            "Epoch 51/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5928 - accuracy: 0.6982\n",
            "Epoch 52/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5933 - accuracy: 0.6854\n",
            "Epoch 53/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5837 - accuracy: 0.6616\n",
            "Epoch 54/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5906 - accuracy: 0.6948\n",
            "Epoch 55/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5885 - accuracy: 0.6923\n",
            "Epoch 56/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6215 - accuracy: 0.6789\n",
            "Epoch 57/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5733 - accuracy: 0.7105\n",
            "Epoch 58/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5936 - accuracy: 0.6802\n",
            "Epoch 59/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5887 - accuracy: 0.6657\n",
            "Epoch 60/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6129 - accuracy: 0.6644\n",
            "Epoch 61/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5580 - accuracy: 0.7133\n",
            "Epoch 62/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5793 - accuracy: 0.7041\n",
            "Epoch 63/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5969 - accuracy: 0.6935\n",
            "Epoch 64/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5715 - accuracy: 0.6949\n",
            "Epoch 65/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5905 - accuracy: 0.6899\n",
            "Epoch 66/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5705 - accuracy: 0.6977\n",
            "Epoch 67/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5907 - accuracy: 0.6793\n",
            "Epoch 68/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5942 - accuracy: 0.6670\n",
            "Epoch 69/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5779 - accuracy: 0.6861\n",
            "Epoch 70/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5708 - accuracy: 0.6977\n",
            "Epoch 71/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5826 - accuracy: 0.6925\n",
            "Epoch 72/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5701 - accuracy: 0.7139\n",
            "Epoch 73/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5669 - accuracy: 0.7076\n",
            "Epoch 74/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5802 - accuracy: 0.6773\n",
            "Epoch 75/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5439 - accuracy: 0.7220\n",
            "Epoch 76/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5678 - accuracy: 0.7134\n",
            "Epoch 77/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5786 - accuracy: 0.6932\n",
            "Epoch 78/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5673 - accuracy: 0.7025\n",
            "Epoch 79/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5802 - accuracy: 0.6773\n",
            "Epoch 80/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5734 - accuracy: 0.6775\n",
            "Epoch 81/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6082 - accuracy: 0.6802\n",
            "Epoch 82/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5625 - accuracy: 0.6950\n",
            "Epoch 83/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5661 - accuracy: 0.6865\n",
            "Epoch 84/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5571 - accuracy: 0.7500\n",
            "Epoch 85/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5634 - accuracy: 0.7142\n",
            "Epoch 86/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5803 - accuracy: 0.6904\n",
            "Epoch 87/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5694 - accuracy: 0.6970\n",
            "Epoch 88/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5702 - accuracy: 0.6897\n",
            "Epoch 89/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5781 - accuracy: 0.6826\n",
            "Epoch 90/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5934 - accuracy: 0.6730\n",
            "Epoch 91/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5700 - accuracy: 0.7032\n",
            "Epoch 92/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5903 - accuracy: 0.6852\n",
            "Epoch 93/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5747 - accuracy: 0.6827\n",
            "Epoch 94/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5946 - accuracy: 0.6735\n",
            "Epoch 95/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5653 - accuracy: 0.6948\n",
            "Epoch 96/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5518 - accuracy: 0.6926\n",
            "Epoch 97/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5824 - accuracy: 0.6730\n",
            "Epoch 98/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5585 - accuracy: 0.7047\n",
            "Epoch 99/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5970 - accuracy: 0.6662\n",
            "Epoch 100/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.6012 - accuracy: 0.6649\n",
            "Epoch 101/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5803 - accuracy: 0.6925\n",
            "Epoch 102/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5535 - accuracy: 0.7080\n",
            "Epoch 103/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5741 - accuracy: 0.7004\n",
            "Epoch 104/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5851 - accuracy: 0.6803\n",
            "Epoch 105/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5688 - accuracy: 0.6949\n",
            "Epoch 106/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5814 - accuracy: 0.6915\n",
            "Epoch 107/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5827 - accuracy: 0.6976\n",
            "Epoch 108/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5578 - accuracy: 0.7092\n",
            "Epoch 109/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5671 - accuracy: 0.7024\n",
            "Epoch 110/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5743 - accuracy: 0.6994\n",
            "Epoch 111/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5691 - accuracy: 0.7125\n",
            "Epoch 112/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5873 - accuracy: 0.6779\n",
            "Epoch 113/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5561 - accuracy: 0.7168\n",
            "Epoch 114/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5782 - accuracy: 0.6963\n",
            "Epoch 115/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5818 - accuracy: 0.6852\n",
            "Epoch 116/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5412 - accuracy: 0.7245\n",
            "Epoch 117/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5713 - accuracy: 0.6888\n",
            "Epoch 118/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5772 - accuracy: 0.7027\n",
            "Epoch 119/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5801 - accuracy: 0.7175\n",
            "Epoch 120/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5456 - accuracy: 0.7162\n",
            "Epoch 121/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5785 - accuracy: 0.6830\n",
            "Epoch 122/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5689 - accuracy: 0.6977\n",
            "Epoch 123/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5646 - accuracy: 0.7067\n",
            "Epoch 124/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5513 - accuracy: 0.7185\n",
            "Epoch 125/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5643 - accuracy: 0.6973\n",
            "Epoch 126/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5791 - accuracy: 0.6821\n",
            "Epoch 127/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5632 - accuracy: 0.7074\n",
            "Epoch 128/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5612 - accuracy: 0.7063\n",
            "Epoch 129/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5813 - accuracy: 0.6779\n",
            "Epoch 130/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5687 - accuracy: 0.6761\n",
            "Epoch 131/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5783 - accuracy: 0.6888\n",
            "Epoch 132/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5864 - accuracy: 0.6857\n",
            "Epoch 133/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5323 - accuracy: 0.7347\n",
            "Epoch 134/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5519 - accuracy: 0.6936\n",
            "Epoch 135/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5603 - accuracy: 0.7161\n",
            "Epoch 136/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5550 - accuracy: 0.7033\n",
            "Epoch 137/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5479 - accuracy: 0.7071\n",
            "Epoch 138/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5472 - accuracy: 0.7010\n",
            "Epoch 139/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5618 - accuracy: 0.7123\n",
            "Epoch 140/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5636 - accuracy: 0.6881\n",
            "Epoch 141/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5493 - accuracy: 0.7098\n",
            "Epoch 142/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5600 - accuracy: 0.7045\n",
            "Epoch 143/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5479 - accuracy: 0.7016\n",
            "Epoch 144/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5857 - accuracy: 0.6984\n",
            "Epoch 145/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5525 - accuracy: 0.6976\n",
            "Epoch 146/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5316 - accuracy: 0.7316\n",
            "Epoch 147/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5488 - accuracy: 0.7081\n",
            "Epoch 148/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5744 - accuracy: 0.6948\n",
            "Epoch 149/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5487 - accuracy: 0.7126\n",
            "Epoch 150/150\n",
            "77/77 [==============================] - 0s 1ms/step - loss: 0.5442 - accuracy: 0.6896\n",
            "Model trained!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8GuQLxVnmLs"
      },
      "source": [
        "## 4. Evaluate Model\n",
        "\n",
        "We have trained our neural network on the entire dataset and we can evaluate the performance of the network on the same dataset.\n",
        "\n",
        "\n",
        "This will only give us an idea of how well we have modeled the dataset, but no idea of how well the algorithm might perform on new data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KvwAijVnk8p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a8db797-3b57-4577-e129-25567614ac95"
      },
      "source": [
        "# evaluate the model\n",
        "scores = model.evaluate(X, Y)\n",
        "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 998us/step - loss: 0.5914 - accuracy: 0.6536\n",
            "\n",
            "accuracy: 65.36%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8M-sc-xjnq1M"
      },
      "source": [
        "## 5. Make predictions\n",
        "\n",
        "Making predictions is as easy as calling the ***predict()*** function on the model. We are using a sigmoid activation function on the output layer, so the predictions will be a probability in the range between 0 and 1. We can easily convert them into a crisp binary prediction for this classification task by rounding them.\n",
        "\n",
        "\n",
        "We can call the ***predict_classes()*** function on the model to predict crisp classes directly.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOSjMfECn29G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f3a82e1-0019-4099-9359-6d732d88f61a"
      },
      "source": [
        "# make class predictions with the model\n",
        "predictions = model.predict_classes(X)\n",
        "\n",
        "# summarize the first 5 cases\n",
        "for i in range(5):\n",
        "\tprint('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], Y[i]))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0] => 1 (expected 1)\n",
            "[1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0] => 0 (expected 0)\n",
            "[8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0] => 1 (expected 1)\n",
            "[1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0] => 0 (expected 0)\n",
            "[0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0] => 0 (expected 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
            "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RfXssV5BpfeJ"
      },
      "source": [
        "# Automatic data split\n",
        "\n",
        "Let's update the code to train the model on a sub-set of the whole dataset (the training set) and use another part for evaluation.\n",
        "\n",
        "We'll use 67% for training and 33% for testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlddJn9Yprjd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1135d27-4c64-4fa1-8216-769cd237de9a"
      },
      "source": [
        "# create new model\n",
        "model = create_model()\n",
        "\n",
        "# compile the model\n",
        "model.compile(loss = \"binary_crossentropy\", optimizer = \"adam\", metrics = ['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "model.fit(X, Y, validation_split=0.33, epochs=150, batch_size=10)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "52/52 [==============================] - 1s 5ms/step - loss: 11.9059 - accuracy: 0.4789 - val_loss: 4.6684 - val_accuracy: 0.5984\n",
            "Epoch 2/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 6.1085 - accuracy: 0.4647 - val_loss: 2.6336 - val_accuracy: 0.4961\n",
            "Epoch 3/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.0479 - accuracy: 0.5415 - val_loss: 2.0200 - val_accuracy: 0.5551\n",
            "Epoch 4/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.8023 - accuracy: 0.5698 - val_loss: 1.4907 - val_accuracy: 0.5276\n",
            "Epoch 5/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.1539 - accuracy: 0.5849 - val_loss: 1.0508 - val_accuracy: 0.6260\n",
            "Epoch 6/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8956 - accuracy: 0.6402 - val_loss: 0.9761 - val_accuracy: 0.5984\n",
            "Epoch 7/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7850 - accuracy: 0.6914 - val_loss: 0.8159 - val_accuracy: 0.6772\n",
            "Epoch 8/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8298 - accuracy: 0.6389 - val_loss: 0.8049 - val_accuracy: 0.6457\n",
            "Epoch 9/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8194 - accuracy: 0.6672 - val_loss: 0.8184 - val_accuracy: 0.6102\n",
            "Epoch 10/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7717 - accuracy: 0.6278 - val_loss: 0.7544 - val_accuracy: 0.6693\n",
            "Epoch 11/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7153 - accuracy: 0.6783 - val_loss: 0.8202 - val_accuracy: 0.6457\n",
            "Epoch 12/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6195 - accuracy: 0.7281 - val_loss: 0.8020 - val_accuracy: 0.6417\n",
            "Epoch 13/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6872 - accuracy: 0.6832 - val_loss: 0.7868 - val_accuracy: 0.6614\n",
            "Epoch 14/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6672 - accuracy: 0.6689 - val_loss: 0.7328 - val_accuracy: 0.6772\n",
            "Epoch 15/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6438 - accuracy: 0.6852 - val_loss: 0.9340 - val_accuracy: 0.4843\n",
            "Epoch 16/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6686 - accuracy: 0.6411 - val_loss: 0.7758 - val_accuracy: 0.6772\n",
            "Epoch 17/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7005 - accuracy: 0.6879 - val_loss: 0.8143 - val_accuracy: 0.6929\n",
            "Epoch 18/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6983 - accuracy: 0.6675 - val_loss: 0.7241 - val_accuracy: 0.6654\n",
            "Epoch 19/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6498 - accuracy: 0.6847 - val_loss: 0.6725 - val_accuracy: 0.6850\n",
            "Epoch 20/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6830 - accuracy: 0.6764 - val_loss: 0.7339 - val_accuracy: 0.7008\n",
            "Epoch 21/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6505 - accuracy: 0.6947 - val_loss: 0.6802 - val_accuracy: 0.6772\n",
            "Epoch 22/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5800 - accuracy: 0.7113 - val_loss: 0.6824 - val_accuracy: 0.6693\n",
            "Epoch 23/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6074 - accuracy: 0.6849 - val_loss: 0.7331 - val_accuracy: 0.6378\n",
            "Epoch 24/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6678 - accuracy: 0.6669 - val_loss: 0.9031 - val_accuracy: 0.4685\n",
            "Epoch 25/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6941 - accuracy: 0.6726 - val_loss: 0.7072 - val_accuracy: 0.6850\n",
            "Epoch 26/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6483 - accuracy: 0.7067 - val_loss: 0.6626 - val_accuracy: 0.6850\n",
            "Epoch 27/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7353 - val_loss: 0.7230 - val_accuracy: 0.6654\n",
            "Epoch 28/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5657 - accuracy: 0.7218 - val_loss: 0.6691 - val_accuracy: 0.6614\n",
            "Epoch 29/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6186 - accuracy: 0.6962 - val_loss: 0.6616 - val_accuracy: 0.6732\n",
            "Epoch 30/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6027 - accuracy: 0.7006 - val_loss: 0.8056 - val_accuracy: 0.6496\n",
            "Epoch 31/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6318 - accuracy: 0.7089 - val_loss: 0.7076 - val_accuracy: 0.6417\n",
            "Epoch 32/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5762 - accuracy: 0.7173 - val_loss: 0.6460 - val_accuracy: 0.6850\n",
            "Epoch 33/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6224 - accuracy: 0.6885 - val_loss: 0.7162 - val_accuracy: 0.6811\n",
            "Epoch 34/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5565 - accuracy: 0.7287 - val_loss: 0.7331 - val_accuracy: 0.6654\n",
            "Epoch 35/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6502 - accuracy: 0.6899 - val_loss: 0.6687 - val_accuracy: 0.7008\n",
            "Epoch 36/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5975 - accuracy: 0.7086 - val_loss: 0.6326 - val_accuracy: 0.6890\n",
            "Epoch 37/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6180 - accuracy: 0.6628 - val_loss: 0.6326 - val_accuracy: 0.6929\n",
            "Epoch 38/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6098 - accuracy: 0.7189 - val_loss: 0.6289 - val_accuracy: 0.7047\n",
            "Epoch 39/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6240 - accuracy: 0.6758 - val_loss: 0.7439 - val_accuracy: 0.6811\n",
            "Epoch 40/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6207 - accuracy: 0.7151 - val_loss: 0.6502 - val_accuracy: 0.6772\n",
            "Epoch 41/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7642 - val_loss: 0.6544 - val_accuracy: 0.6929\n",
            "Epoch 42/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7018 - accuracy: 0.7079 - val_loss: 0.6468 - val_accuracy: 0.6890\n",
            "Epoch 43/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6328 - accuracy: 0.7092 - val_loss: 0.6503 - val_accuracy: 0.7008\n",
            "Epoch 44/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7247 - val_loss: 0.6379 - val_accuracy: 0.7087\n",
            "Epoch 45/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5688 - accuracy: 0.7258 - val_loss: 0.6492 - val_accuracy: 0.7087\n",
            "Epoch 46/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7416 - val_loss: 0.7336 - val_accuracy: 0.6614\n",
            "Epoch 47/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6040 - accuracy: 0.7090 - val_loss: 0.6503 - val_accuracy: 0.6772\n",
            "Epoch 48/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7434 - val_loss: 0.6444 - val_accuracy: 0.6732\n",
            "Epoch 49/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5705 - accuracy: 0.7231 - val_loss: 0.6732 - val_accuracy: 0.6850\n",
            "Epoch 50/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5868 - accuracy: 0.7176 - val_loss: 0.6285 - val_accuracy: 0.6890\n",
            "Epoch 51/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5818 - accuracy: 0.7124 - val_loss: 0.6295 - val_accuracy: 0.7047\n",
            "Epoch 52/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7264 - val_loss: 0.6454 - val_accuracy: 0.6811\n",
            "Epoch 53/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5686 - accuracy: 0.7389 - val_loss: 0.6833 - val_accuracy: 0.6811\n",
            "Epoch 54/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5883 - accuracy: 0.7041 - val_loss: 0.6536 - val_accuracy: 0.6811\n",
            "Epoch 55/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5675 - accuracy: 0.7183 - val_loss: 0.6773 - val_accuracy: 0.6811\n",
            "Epoch 56/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5296 - accuracy: 0.7633 - val_loss: 0.6418 - val_accuracy: 0.6850\n",
            "Epoch 57/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5515 - accuracy: 0.7457 - val_loss: 0.6367 - val_accuracy: 0.6811\n",
            "Epoch 58/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7315 - val_loss: 0.6502 - val_accuracy: 0.6772\n",
            "Epoch 59/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5719 - accuracy: 0.7117 - val_loss: 0.6744 - val_accuracy: 0.6811\n",
            "Epoch 60/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7604 - val_loss: 0.6515 - val_accuracy: 0.6693\n",
            "Epoch 61/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.7117 - val_loss: 0.6382 - val_accuracy: 0.6732\n",
            "Epoch 62/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7192 - val_loss: 0.6232 - val_accuracy: 0.6850\n",
            "Epoch 63/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5480 - accuracy: 0.7061 - val_loss: 0.6457 - val_accuracy: 0.6811\n",
            "Epoch 64/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5844 - accuracy: 0.7122 - val_loss: 0.7263 - val_accuracy: 0.5984\n",
            "Epoch 65/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5722 - accuracy: 0.7306 - val_loss: 0.6332 - val_accuracy: 0.6969\n",
            "Epoch 66/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7466 - val_loss: 0.6586 - val_accuracy: 0.6732\n",
            "Epoch 67/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6205 - accuracy: 0.6934 - val_loss: 0.6210 - val_accuracy: 0.6929\n",
            "Epoch 68/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6115 - accuracy: 0.6884 - val_loss: 0.6189 - val_accuracy: 0.7087\n",
            "Epoch 69/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5346 - accuracy: 0.7647 - val_loss: 0.6295 - val_accuracy: 0.6890\n",
            "Epoch 70/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5991 - accuracy: 0.7058 - val_loss: 0.6405 - val_accuracy: 0.6693\n",
            "Epoch 71/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7277 - val_loss: 0.7100 - val_accuracy: 0.6614\n",
            "Epoch 72/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5780 - accuracy: 0.7294 - val_loss: 0.6134 - val_accuracy: 0.7008\n",
            "Epoch 73/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7524 - val_loss: 0.8164 - val_accuracy: 0.5591\n",
            "Epoch 74/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6318 - accuracy: 0.7095 - val_loss: 0.6465 - val_accuracy: 0.6969\n",
            "Epoch 75/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7464 - val_loss: 0.6269 - val_accuracy: 0.6811\n",
            "Epoch 76/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5427 - accuracy: 0.7235 - val_loss: 0.8007 - val_accuracy: 0.6850\n",
            "Epoch 77/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5848 - accuracy: 0.7175 - val_loss: 0.6141 - val_accuracy: 0.6890\n",
            "Epoch 78/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7321 - val_loss: 0.6037 - val_accuracy: 0.7126\n",
            "Epoch 79/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7511 - val_loss: 0.6326 - val_accuracy: 0.6575\n",
            "Epoch 80/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.7236 - val_loss: 0.6458 - val_accuracy: 0.6614\n",
            "Epoch 81/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.7536 - val_loss: 0.6295 - val_accuracy: 0.6614\n",
            "Epoch 82/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7675 - val_loss: 0.6947 - val_accuracy: 0.6378\n",
            "Epoch 83/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5778 - accuracy: 0.7315 - val_loss: 0.6150 - val_accuracy: 0.6969\n",
            "Epoch 84/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5382 - accuracy: 0.7199 - val_loss: 0.6488 - val_accuracy: 0.6693\n",
            "Epoch 85/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5274 - accuracy: 0.7692 - val_loss: 0.5875 - val_accuracy: 0.7165\n",
            "Epoch 86/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5270 - accuracy: 0.7693 - val_loss: 0.6279 - val_accuracy: 0.6693\n",
            "Epoch 87/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5251 - accuracy: 0.7465 - val_loss: 0.6233 - val_accuracy: 0.6693\n",
            "Epoch 88/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7268 - val_loss: 0.6624 - val_accuracy: 0.6732\n",
            "Epoch 89/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7270 - val_loss: 0.6514 - val_accuracy: 0.6772\n",
            "Epoch 90/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7430 - val_loss: 0.6050 - val_accuracy: 0.7008\n",
            "Epoch 91/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5480 - accuracy: 0.7135 - val_loss: 0.6054 - val_accuracy: 0.7047\n",
            "Epoch 92/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7408 - val_loss: 0.6565 - val_accuracy: 0.6654\n",
            "Epoch 93/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.7405 - val_loss: 0.6383 - val_accuracy: 0.6850\n",
            "Epoch 94/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.7712 - val_loss: 0.6354 - val_accuracy: 0.6732\n",
            "Epoch 95/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7284 - val_loss: 0.6247 - val_accuracy: 0.6772\n",
            "Epoch 96/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7454 - val_loss: 0.5978 - val_accuracy: 0.6929\n",
            "Epoch 97/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5642 - accuracy: 0.7114 - val_loss: 0.5929 - val_accuracy: 0.7165\n",
            "Epoch 98/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.7695 - val_loss: 0.6018 - val_accuracy: 0.6890\n",
            "Epoch 99/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7373 - val_loss: 0.6784 - val_accuracy: 0.6890\n",
            "Epoch 100/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6121 - accuracy: 0.7398 - val_loss: 0.6291 - val_accuracy: 0.6850\n",
            "Epoch 101/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7319 - val_loss: 0.6221 - val_accuracy: 0.6850\n",
            "Epoch 102/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.7370 - val_loss: 0.5925 - val_accuracy: 0.7087\n",
            "Epoch 103/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.7481 - val_loss: 0.5972 - val_accuracy: 0.7008\n",
            "Epoch 104/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7231 - val_loss: 0.6734 - val_accuracy: 0.6417\n",
            "Epoch 105/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.7693 - val_loss: 0.6083 - val_accuracy: 0.6811\n",
            "Epoch 106/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7338 - val_loss: 0.5802 - val_accuracy: 0.7008\n",
            "Epoch 107/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4523 - accuracy: 0.7941 - val_loss: 0.6178 - val_accuracy: 0.6850\n",
            "Epoch 108/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5086 - accuracy: 0.7829 - val_loss: 0.6659 - val_accuracy: 0.6732\n",
            "Epoch 109/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4949 - accuracy: 0.7423 - val_loss: 0.6409 - val_accuracy: 0.6732\n",
            "Epoch 110/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7326 - val_loss: 0.6181 - val_accuracy: 0.6929\n",
            "Epoch 111/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5261 - accuracy: 0.7365 - val_loss: 0.6975 - val_accuracy: 0.6732\n",
            "Epoch 112/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7293 - val_loss: 0.5954 - val_accuracy: 0.6890\n",
            "Epoch 113/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7481 - val_loss: 0.6433 - val_accuracy: 0.6850\n",
            "Epoch 114/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5167 - accuracy: 0.7482 - val_loss: 0.6127 - val_accuracy: 0.7008\n",
            "Epoch 115/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.7763 - val_loss: 0.5816 - val_accuracy: 0.6929\n",
            "Epoch 116/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.7493 - val_loss: 0.7104 - val_accuracy: 0.6575\n",
            "Epoch 117/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4894 - accuracy: 0.7476 - val_loss: 0.6105 - val_accuracy: 0.6850\n",
            "Epoch 118/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7218 - val_loss: 0.6143 - val_accuracy: 0.7047\n",
            "Epoch 119/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7827 - val_loss: 0.6814 - val_accuracy: 0.6732\n",
            "Epoch 120/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.7580 - val_loss: 0.6164 - val_accuracy: 0.7047\n",
            "Epoch 121/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5230 - accuracy: 0.7102 - val_loss: 0.6110 - val_accuracy: 0.7126\n",
            "Epoch 122/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5114 - accuracy: 0.7422 - val_loss: 0.7056 - val_accuracy: 0.6496\n",
            "Epoch 123/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5602 - accuracy: 0.7543 - val_loss: 0.5837 - val_accuracy: 0.6811\n",
            "Epoch 124/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.7693 - val_loss: 0.6166 - val_accuracy: 0.7047\n",
            "Epoch 125/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5119 - accuracy: 0.7661 - val_loss: 0.6046 - val_accuracy: 0.7087\n",
            "Epoch 126/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7325 - val_loss: 0.6486 - val_accuracy: 0.6772\n",
            "Epoch 127/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7633 - val_loss: 0.5962 - val_accuracy: 0.6811\n",
            "Epoch 128/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.7403 - val_loss: 0.6048 - val_accuracy: 0.7008\n",
            "Epoch 129/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.7502 - val_loss: 0.6135 - val_accuracy: 0.7244\n",
            "Epoch 130/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.7360 - val_loss: 0.6406 - val_accuracy: 0.6811\n",
            "Epoch 131/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5275 - accuracy: 0.7712 - val_loss: 0.5887 - val_accuracy: 0.7323\n",
            "Epoch 132/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.7701 - val_loss: 0.6022 - val_accuracy: 0.6772\n",
            "Epoch 133/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.7286 - val_loss: 0.7141 - val_accuracy: 0.6142\n",
            "Epoch 134/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5104 - accuracy: 0.7498 - val_loss: 0.5794 - val_accuracy: 0.6929\n",
            "Epoch 135/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5064 - accuracy: 0.7448 - val_loss: 0.5821 - val_accuracy: 0.7244\n",
            "Epoch 136/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.7768 - val_loss: 0.7040 - val_accuracy: 0.6339\n",
            "Epoch 137/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.7450 - val_loss: 0.6349 - val_accuracy: 0.6969\n",
            "Epoch 138/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4865 - accuracy: 0.7647 - val_loss: 0.5862 - val_accuracy: 0.7008\n",
            "Epoch 139/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4854 - accuracy: 0.7668 - val_loss: 0.7211 - val_accuracy: 0.6535\n",
            "Epoch 140/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5264 - accuracy: 0.7170 - val_loss: 0.5857 - val_accuracy: 0.6850\n",
            "Epoch 141/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5110 - accuracy: 0.7313 - val_loss: 0.5956 - val_accuracy: 0.6850\n",
            "Epoch 142/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5582 - accuracy: 0.7293 - val_loss: 0.5962 - val_accuracy: 0.7205\n",
            "Epoch 143/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4538 - accuracy: 0.7951 - val_loss: 0.5845 - val_accuracy: 0.7047\n",
            "Epoch 144/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.7476 - val_loss: 0.6082 - val_accuracy: 0.6890\n",
            "Epoch 145/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.7459 - val_loss: 0.5929 - val_accuracy: 0.7126\n",
            "Epoch 146/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7694 - val_loss: 0.5828 - val_accuracy: 0.7165\n",
            "Epoch 147/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.7430 - val_loss: 0.5855 - val_accuracy: 0.7205\n",
            "Epoch 148/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.8145 - val_loss: 0.5592 - val_accuracy: 0.7165\n",
            "Epoch 149/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.7747 - val_loss: 0.6363 - val_accuracy: 0.6929\n",
            "Epoch 150/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.7780 - val_loss: 0.5660 - val_accuracy: 0.7165\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff1d98fdc90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trISU5HyoK3N"
      },
      "source": [
        "# Manual Data Split\n",
        "\n",
        "Evaluate the model with manual data split. Let's also use 67% for training and 33% for testing.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfXkri28JwSl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c540728c-4e0e-4128-a962-632767fd8449"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# split into 67% for train and 33% for test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42) \n",
        "\n",
        "#create a new model\n",
        "model = create_model()\n",
        "\n",
        "#compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "#train the model\n",
        "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=150, batch_size=10) "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "52/52 [==============================] - 1s 5ms/step - loss: 11.3621 - accuracy: 0.3457 - val_loss: 2.4291 - val_accuracy: 0.6024\n",
            "Epoch 2/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 2.2436 - accuracy: 0.5623 - val_loss: 1.8186 - val_accuracy: 0.6142\n",
            "Epoch 3/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.6965 - accuracy: 0.6308 - val_loss: 1.6199 - val_accuracy: 0.6260\n",
            "Epoch 4/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.5246 - accuracy: 0.5795 - val_loss: 1.4376 - val_accuracy: 0.6063\n",
            "Epoch 5/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.2804 - accuracy: 0.6036 - val_loss: 1.3305 - val_accuracy: 0.6299\n",
            "Epoch 6/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.2036 - accuracy: 0.6256 - val_loss: 1.2901 - val_accuracy: 0.5906\n",
            "Epoch 7/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0325 - accuracy: 0.6573 - val_loss: 1.1977 - val_accuracy: 0.5945\n",
            "Epoch 8/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.0552 - accuracy: 0.6390 - val_loss: 1.0758 - val_accuracy: 0.6654\n",
            "Epoch 9/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 1.2097 - accuracy: 0.6186 - val_loss: 1.0097 - val_accuracy: 0.6535\n",
            "Epoch 10/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9109 - accuracy: 0.6589 - val_loss: 0.9625 - val_accuracy: 0.6693\n",
            "Epoch 11/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9172 - accuracy: 0.6503 - val_loss: 0.9566 - val_accuracy: 0.6772\n",
            "Epoch 12/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8687 - accuracy: 0.6647 - val_loss: 0.9937 - val_accuracy: 0.6378\n",
            "Epoch 13/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.9800 - accuracy: 0.6273 - val_loss: 0.9043 - val_accuracy: 0.6457\n",
            "Epoch 14/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8346 - accuracy: 0.6423 - val_loss: 0.8440 - val_accuracy: 0.6732\n",
            "Epoch 15/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.8109 - accuracy: 0.6303 - val_loss: 0.8383 - val_accuracy: 0.6654\n",
            "Epoch 16/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7673 - accuracy: 0.6495 - val_loss: 0.8429 - val_accuracy: 0.6457\n",
            "Epoch 17/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7267 - accuracy: 0.6672 - val_loss: 0.7809 - val_accuracy: 0.6654\n",
            "Epoch 18/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7521 - accuracy: 0.6350 - val_loss: 0.7826 - val_accuracy: 0.6654\n",
            "Epoch 19/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6975 - accuracy: 0.6394 - val_loss: 0.7665 - val_accuracy: 0.7008\n",
            "Epoch 20/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6483 - accuracy: 0.6939 - val_loss: 0.7157 - val_accuracy: 0.6614\n",
            "Epoch 21/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6743 - accuracy: 0.6867 - val_loss: 0.7969 - val_accuracy: 0.6417\n",
            "Epoch 22/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7267 - accuracy: 0.6636 - val_loss: 0.6845 - val_accuracy: 0.6811\n",
            "Epoch 23/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6713 - accuracy: 0.6589 - val_loss: 0.7371 - val_accuracy: 0.6575\n",
            "Epoch 24/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.7121 - accuracy: 0.6637 - val_loss: 0.6820 - val_accuracy: 0.6693\n",
            "Epoch 25/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6294 - accuracy: 0.6885 - val_loss: 0.7531 - val_accuracy: 0.6811\n",
            "Epoch 26/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6628 - accuracy: 0.6638 - val_loss: 0.6795 - val_accuracy: 0.6929\n",
            "Epoch 27/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6671 - accuracy: 0.6668 - val_loss: 0.6556 - val_accuracy: 0.6890\n",
            "Epoch 28/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6139 - accuracy: 0.7003 - val_loss: 0.6610 - val_accuracy: 0.6890\n",
            "Epoch 29/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6650 - accuracy: 0.7014 - val_loss: 0.6458 - val_accuracy: 0.6929\n",
            "Epoch 30/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5930 - accuracy: 0.7083 - val_loss: 0.6564 - val_accuracy: 0.6693\n",
            "Epoch 31/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6214 - accuracy: 0.6719 - val_loss: 0.6382 - val_accuracy: 0.6929\n",
            "Epoch 32/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5947 - accuracy: 0.6986 - val_loss: 0.7417 - val_accuracy: 0.6339\n",
            "Epoch 33/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6165 - accuracy: 0.6968 - val_loss: 0.6992 - val_accuracy: 0.6811\n",
            "Epoch 34/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6081 - accuracy: 0.7129 - val_loss: 0.6899 - val_accuracy: 0.6890\n",
            "Epoch 35/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6619 - accuracy: 0.6886 - val_loss: 0.7552 - val_accuracy: 0.6890\n",
            "Epoch 36/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6669 - accuracy: 0.6418 - val_loss: 0.6991 - val_accuracy: 0.6732\n",
            "Epoch 37/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5869 - accuracy: 0.7219 - val_loss: 0.7139 - val_accuracy: 0.6496\n",
            "Epoch 38/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6010 - accuracy: 0.6954 - val_loss: 0.8329 - val_accuracy: 0.6654\n",
            "Epoch 39/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6787 - accuracy: 0.6871 - val_loss: 0.8078 - val_accuracy: 0.6772\n",
            "Epoch 40/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.7185 - accuracy: 0.6776 - val_loss: 0.6284 - val_accuracy: 0.7087\n",
            "Epoch 41/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5320 - accuracy: 0.7664 - val_loss: 0.6310 - val_accuracy: 0.7165\n",
            "Epoch 42/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5483 - accuracy: 0.7409 - val_loss: 0.6221 - val_accuracy: 0.7008\n",
            "Epoch 43/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5903 - accuracy: 0.7106 - val_loss: 0.6954 - val_accuracy: 0.6811\n",
            "Epoch 44/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5791 - accuracy: 0.7277 - val_loss: 0.6820 - val_accuracy: 0.6811\n",
            "Epoch 45/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6320 - accuracy: 0.6983 - val_loss: 0.6218 - val_accuracy: 0.6969\n",
            "Epoch 46/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6687 - accuracy: 0.6816 - val_loss: 0.6341 - val_accuracy: 0.6890\n",
            "Epoch 47/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6094 - accuracy: 0.6907 - val_loss: 0.6221 - val_accuracy: 0.7008\n",
            "Epoch 48/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.7263 - val_loss: 0.8892 - val_accuracy: 0.6339\n",
            "Epoch 49/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6396 - accuracy: 0.6872 - val_loss: 0.6389 - val_accuracy: 0.6969\n",
            "Epoch 50/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6073 - accuracy: 0.7164 - val_loss: 0.6134 - val_accuracy: 0.7244\n",
            "Epoch 51/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6104 - accuracy: 0.6996 - val_loss: 0.6157 - val_accuracy: 0.7283\n",
            "Epoch 52/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6022 - accuracy: 0.7069 - val_loss: 0.8478 - val_accuracy: 0.6496\n",
            "Epoch 53/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6695 - accuracy: 0.6892 - val_loss: 0.6435 - val_accuracy: 0.7008\n",
            "Epoch 54/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5867 - accuracy: 0.6963 - val_loss: 0.6565 - val_accuracy: 0.6732\n",
            "Epoch 55/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5657 - accuracy: 0.7026 - val_loss: 0.6358 - val_accuracy: 0.6929\n",
            "Epoch 56/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5946 - accuracy: 0.6838 - val_loss: 0.6326 - val_accuracy: 0.6772\n",
            "Epoch 57/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.7493 - val_loss: 0.6260 - val_accuracy: 0.6890\n",
            "Epoch 58/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6121 - accuracy: 0.7013 - val_loss: 0.6354 - val_accuracy: 0.6969\n",
            "Epoch 59/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5416 - accuracy: 0.7455 - val_loss: 0.6119 - val_accuracy: 0.6890\n",
            "Epoch 60/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.7488 - val_loss: 0.6230 - val_accuracy: 0.6969\n",
            "Epoch 61/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5715 - accuracy: 0.7409 - val_loss: 0.6539 - val_accuracy: 0.6890\n",
            "Epoch 62/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5998 - accuracy: 0.7078 - val_loss: 0.6324 - val_accuracy: 0.7047\n",
            "Epoch 63/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5884 - accuracy: 0.7113 - val_loss: 0.6731 - val_accuracy: 0.6890\n",
            "Epoch 64/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5452 - accuracy: 0.7431 - val_loss: 0.6237 - val_accuracy: 0.6732\n",
            "Epoch 65/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6056 - accuracy: 0.7153 - val_loss: 0.6261 - val_accuracy: 0.7008\n",
            "Epoch 66/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5953 - accuracy: 0.7294 - val_loss: 0.6305 - val_accuracy: 0.7047\n",
            "Epoch 67/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5903 - accuracy: 0.6899 - val_loss: 0.6127 - val_accuracy: 0.7165\n",
            "Epoch 68/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5442 - accuracy: 0.7442 - val_loss: 0.5967 - val_accuracy: 0.6969\n",
            "Epoch 69/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7324 - val_loss: 0.6555 - val_accuracy: 0.7008\n",
            "Epoch 70/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.7001 - val_loss: 0.6699 - val_accuracy: 0.7008\n",
            "Epoch 71/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6073 - accuracy: 0.7097 - val_loss: 0.5997 - val_accuracy: 0.6969\n",
            "Epoch 72/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5635 - accuracy: 0.7417 - val_loss: 0.5978 - val_accuracy: 0.7047\n",
            "Epoch 73/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7619 - val_loss: 0.6121 - val_accuracy: 0.6772\n",
            "Epoch 74/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5501 - accuracy: 0.7271 - val_loss: 0.6038 - val_accuracy: 0.6969\n",
            "Epoch 75/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5595 - accuracy: 0.7109 - val_loss: 0.6044 - val_accuracy: 0.7165\n",
            "Epoch 76/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5485 - accuracy: 0.7157 - val_loss: 0.6710 - val_accuracy: 0.7008\n",
            "Epoch 77/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5769 - accuracy: 0.6909 - val_loss: 0.6030 - val_accuracy: 0.6969\n",
            "Epoch 78/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7615 - val_loss: 0.6063 - val_accuracy: 0.6929\n",
            "Epoch 79/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5296 - accuracy: 0.7557 - val_loss: 0.6547 - val_accuracy: 0.6772\n",
            "Epoch 80/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5896 - accuracy: 0.7193 - val_loss: 0.5957 - val_accuracy: 0.7244\n",
            "Epoch 81/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7309 - val_loss: 0.6041 - val_accuracy: 0.6811\n",
            "Epoch 82/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7428 - val_loss: 0.6302 - val_accuracy: 0.7047\n",
            "Epoch 83/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5689 - accuracy: 0.7103 - val_loss: 0.6189 - val_accuracy: 0.6535\n",
            "Epoch 84/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7294 - val_loss: 0.6037 - val_accuracy: 0.7205\n",
            "Epoch 85/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5506 - accuracy: 0.7318 - val_loss: 0.6248 - val_accuracy: 0.6929\n",
            "Epoch 86/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5794 - accuracy: 0.7084 - val_loss: 0.7292 - val_accuracy: 0.6969\n",
            "Epoch 87/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5830 - accuracy: 0.7238 - val_loss: 0.5905 - val_accuracy: 0.7047\n",
            "Epoch 88/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5707 - accuracy: 0.7027 - val_loss: 0.6052 - val_accuracy: 0.7244\n",
            "Epoch 89/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5835 - accuracy: 0.7175 - val_loss: 0.6163 - val_accuracy: 0.6969\n",
            "Epoch 90/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5584 - accuracy: 0.7193 - val_loss: 0.5885 - val_accuracy: 0.6969\n",
            "Epoch 91/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7418 - val_loss: 0.6217 - val_accuracy: 0.7283\n",
            "Epoch 92/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.7571 - val_loss: 0.6249 - val_accuracy: 0.7008\n",
            "Epoch 93/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7378 - val_loss: 0.7516 - val_accuracy: 0.6890\n",
            "Epoch 94/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6404 - accuracy: 0.6933 - val_loss: 0.5882 - val_accuracy: 0.6929\n",
            "Epoch 95/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5448 - accuracy: 0.7324 - val_loss: 0.7276 - val_accuracy: 0.6969\n",
            "Epoch 96/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5864 - accuracy: 0.7148 - val_loss: 0.5962 - val_accuracy: 0.7283\n",
            "Epoch 97/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.7639 - val_loss: 0.5896 - val_accuracy: 0.6890\n",
            "Epoch 98/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7091 - val_loss: 0.5965 - val_accuracy: 0.7244\n",
            "Epoch 99/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7351 - val_loss: 0.7254 - val_accuracy: 0.6890\n",
            "Epoch 100/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5853 - accuracy: 0.7147 - val_loss: 0.7196 - val_accuracy: 0.6732\n",
            "Epoch 101/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7557 - val_loss: 0.6332 - val_accuracy: 0.7165\n",
            "Epoch 102/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.7625 - val_loss: 0.6376 - val_accuracy: 0.6969\n",
            "Epoch 103/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5937 - accuracy: 0.7077 - val_loss: 0.6483 - val_accuracy: 0.6772\n",
            "Epoch 104/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5337 - accuracy: 0.7225 - val_loss: 0.5860 - val_accuracy: 0.7008\n",
            "Epoch 105/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7479 - val_loss: 0.6239 - val_accuracy: 0.7008\n",
            "Epoch 106/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7431 - val_loss: 0.6205 - val_accuracy: 0.7244\n",
            "Epoch 107/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5925 - accuracy: 0.7625 - val_loss: 0.5887 - val_accuracy: 0.7008\n",
            "Epoch 108/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5960 - accuracy: 0.7140 - val_loss: 0.5988 - val_accuracy: 0.7126\n",
            "Epoch 109/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5859 - accuracy: 0.7223 - val_loss: 0.5931 - val_accuracy: 0.7165\n",
            "Epoch 110/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.7168 - val_loss: 0.6310 - val_accuracy: 0.7244\n",
            "Epoch 111/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5985 - accuracy: 0.7320 - val_loss: 0.5860 - val_accuracy: 0.7008\n",
            "Epoch 112/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7391 - val_loss: 0.5846 - val_accuracy: 0.7283\n",
            "Epoch 113/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5171 - accuracy: 0.7633 - val_loss: 0.5828 - val_accuracy: 0.7087\n",
            "Epoch 114/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.7208 - val_loss: 0.5784 - val_accuracy: 0.7087\n",
            "Epoch 115/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.7730 - val_loss: 0.6452 - val_accuracy: 0.7205\n",
            "Epoch 116/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5937 - accuracy: 0.7000 - val_loss: 0.6479 - val_accuracy: 0.7087\n",
            "Epoch 117/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5720 - accuracy: 0.7270 - val_loss: 0.5801 - val_accuracy: 0.7283\n",
            "Epoch 118/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7369 - val_loss: 0.6233 - val_accuracy: 0.7244\n",
            "Epoch 119/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5603 - accuracy: 0.7105 - val_loss: 0.6115 - val_accuracy: 0.6969\n",
            "Epoch 120/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.7023 - val_loss: 0.5968 - val_accuracy: 0.7323\n",
            "Epoch 121/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7307 - val_loss: 0.6499 - val_accuracy: 0.7165\n",
            "Epoch 122/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5592 - accuracy: 0.7206 - val_loss: 0.6109 - val_accuracy: 0.7087\n",
            "Epoch 123/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7285 - val_loss: 0.6010 - val_accuracy: 0.6969\n",
            "Epoch 124/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5258 - accuracy: 0.7456 - val_loss: 0.5896 - val_accuracy: 0.7205\n",
            "Epoch 125/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5311 - accuracy: 0.7756 - val_loss: 0.6184 - val_accuracy: 0.7244\n",
            "Epoch 126/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7668 - val_loss: 0.6032 - val_accuracy: 0.7323\n",
            "Epoch 127/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7444 - val_loss: 0.5897 - val_accuracy: 0.7323\n",
            "Epoch 128/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7464 - val_loss: 0.5786 - val_accuracy: 0.6969\n",
            "Epoch 129/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5241 - accuracy: 0.7481 - val_loss: 0.6437 - val_accuracy: 0.7283\n",
            "Epoch 130/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5284 - accuracy: 0.7196 - val_loss: 0.5940 - val_accuracy: 0.7165\n",
            "Epoch 131/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7621 - val_loss: 0.5855 - val_accuracy: 0.7008\n",
            "Epoch 132/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5474 - accuracy: 0.7408 - val_loss: 0.5836 - val_accuracy: 0.7205\n",
            "Epoch 133/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5107 - accuracy: 0.7388 - val_loss: 0.5961 - val_accuracy: 0.7205\n",
            "Epoch 134/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4959 - accuracy: 0.7724 - val_loss: 0.5832 - val_accuracy: 0.7402\n",
            "Epoch 135/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.4950 - accuracy: 0.7712 - val_loss: 0.5797 - val_accuracy: 0.7126\n",
            "Epoch 136/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5491 - accuracy: 0.7281 - val_loss: 0.6012 - val_accuracy: 0.6969\n",
            "Epoch 137/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5440 - accuracy: 0.7419 - val_loss: 0.6567 - val_accuracy: 0.7087\n",
            "Epoch 138/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.6050 - accuracy: 0.7226 - val_loss: 0.6341 - val_accuracy: 0.7165\n",
            "Epoch 139/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.7460 - val_loss: 0.6002 - val_accuracy: 0.7244\n",
            "Epoch 140/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.7282 - val_loss: 0.5805 - val_accuracy: 0.7205\n",
            "Epoch 141/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5183 - accuracy: 0.7495 - val_loss: 0.5816 - val_accuracy: 0.7283\n",
            "Epoch 142/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7353 - val_loss: 0.5838 - val_accuracy: 0.7087\n",
            "Epoch 143/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.7588 - val_loss: 0.6070 - val_accuracy: 0.6890\n",
            "Epoch 144/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.7474 - val_loss: 0.6018 - val_accuracy: 0.7283\n",
            "Epoch 145/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5161 - accuracy: 0.7308 - val_loss: 0.5822 - val_accuracy: 0.7244\n",
            "Epoch 146/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.7494 - val_loss: 0.5763 - val_accuracy: 0.7126\n",
            "Epoch 147/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.7351 - val_loss: 0.5877 - val_accuracy: 0.7283\n",
            "Epoch 148/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.7913 - val_loss: 0.5814 - val_accuracy: 0.7165\n",
            "Epoch 149/150\n",
            "52/52 [==============================] - 0s 3ms/step - loss: 0.5327 - accuracy: 0.7643 - val_loss: 0.5864 - val_accuracy: 0.7047\n",
            "Epoch 150/150\n",
            "52/52 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.7675 - val_loss: 0.5971 - val_accuracy: 0.7047\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7ff1ce3bb6d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7O4yIPH2PGaj"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}